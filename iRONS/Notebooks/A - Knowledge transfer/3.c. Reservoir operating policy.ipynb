{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Optimisation of the reservoir operating policy\n",
    "In this Notebook we will see why and how to optimise the operating policy of a water reservoir system. An **operating policy** is a function that returns the operational decision to be made at any given time (such as the release volume for the next 24 hours) based on the conditions of the reservoir system (for instance, the reservoir storage, the demand forecast, the time of year, etc.) at that time. Differently from the release/pumping schedulings discussed in the previous Notebooks, which are optimised every time an operational decision must be made, the operating policy is optimised once and then applied forever after (or at least, until a revision of the policy is needed). In other words, the optimisation of the operating policy does not return a set of optimal operational decisions but rather a strategy for making optimal decisions ([Dobson et al, 2019](https://doi.org/10.1016/j.advwatres.2019.04.012)). It follows that, while the optimisation of release/pumping schedulings aims at maximising the benefits against the short- or mid-term forecasts of inflow and demand, the optimisation of the operating policy maximises the long-term benefits. These can be estimated by using (sufficiently long) historical time series or model projections.\n",
    "\n",
    "<left><img src=\"../../util/images/Dam3.gif\" width = \"500px\"><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we consider a simple illustrative system where a reservoir is operated to supply water to a domestic consumption node, while ensuring a minimum environmental flow in the downstream river (also called “environmental compensation flow”) and maintaining the water level in the reservoir within prescribed limits. We use a mathematical model to link all the key variables that represent the reservoir dynamics (inflow, storage and outflows) and use model simulation/optimisation to determine the reservoir operating policy that optimizes the **long-term** (several years) system performance. We use the historical time series of inflows and water demand to estimate such long-term performance. The underpinning assumption here is that the system forcings observed over the past years are representative of the forcings that will drive the system in the future (if this assumption is not sensible, for instance because of ongoing changes that will likely impact the hydrological regime or demand pattern, then one may use model projections of inflow and demand in place of historical observations) \n",
    "<left> <img src=\"../../util/images/system_representation_IO1.png\" width = \"600px\"><left>\n",
    "\n",
    "We will use a simple form of operating policy where the reservoir release is only determined by the storage value, as in the Figure below. Higher storage values are associated to higher releases, which is useful for flood control purposes, whereas at low storage values less water is released to reduce the risk of future water shortages [(Loucks et al., 1981)](https://link.springer.com/book/10.1007/978-3-319-44234-1). FP: I HAVE SIMPLIFIED THIS PART AND REMOVED THE TERM 'POLICY FUNCTION'. I THINK IT IS CONFUSING TO HAVE TWO TERMS (OPERATING POLICY AND POLICY FUNCTION) TO REFER TO THE SAME THING, AND OPERATING POLICY IS MUCH MORE WIDELY USED, SO I WOULD STICK TO THAT. LET'S NOT MAKE THINGS TOO COMPLICATED! \n",
    "<left><img src=\"../../util/images/Policy_function.png\" width = \"400px\"><left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "To run this Notebook we need to import some libraries. **If iRONs is run locally**, the [plotly](https://plot.ly/) must be installed first (it is not available on Anaconda by default). Help on how to install libraries is given here: [How to install libraries](../0%20-%20Tutorials/0.b%20-%20How%20to%20install%20libraries.ipynb). **If iRONs is run on the cloud**, e.g. on [Binder](https://mybinder.org/) or [Microsoft Azure Notebooks](https://notebooks.azure.com/), there is no need to install libraries before importing them. \n",
    "\n",
    "Libraries are imported with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bqplot import pyplot as plt\n",
    "from bqplot import *\n",
    "from bqplot.traits import *\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from platypus import NSGAII, Problem, Real, Integer # Import the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the shape of the operating policy\n",
    "In this notebook we will use an operating policy that returns the release from the reservoir as a piece-wise linear function of the reservoir storage. The function is implemented in a series of submodules, that we can import with the following code: (FP: I HAVE REARRANGE THE TEXT HERE MOVING BITS UP AND DOWN SO TO BETTER ALIGN THE TEXT WITH THE CONTENT OF THE CODE BLOCKS, OTHERWISE THE READER MAY BE A BIT LOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Submodules\n",
    "from Modules.Interactive_release_policy import Interactive_policy_manual, Interactive_policy_auto\n",
    "sys.path.append('../../Functions')\n",
    "from Reservoir_operating_policy.Operating_policy_functions import four_points_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our code, the operating policy uses rescaled release and storage values. Specifically, the storage is scaled by the reservoir active capacity, so that in the operating policy function it varies between 0 (dead storage) and 1 (full storage). The release is scaled with respect to its mean, so that the operating policy returns the fraction (or multiple) of the mean release. \n",
    "The piece-wise linear function representing the operating policy is delineated by 4 points (x0, x1, x2 and x3): the minimimum and maximum (storage,release) points (x0 and x3 respectively), and two inflection points (x1, x2) where the slope of the function changes. The function returns a constant release (for instance, the target demand) when the storages stay between points x1 and x2; the release is reduced if the storage is below x1, or increased if it goes above x2. Let's now attribute a (tentative) value to the coordinates of these points, so that we can visualise the operating policy. For example: (FP: WHERE DO WE DEFINE THE MIN AND MAX STORAGE? UNDECLARED IN THE CODE BELOW... WHY?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System constraints\n",
    "u_mean = 20 # ML/week - the (long-term) mean release   \n",
    "u_min = 2 # ML/week   - the release at minimum storage \n",
    "u_max = 80 # ML/week  - the release at minimum storage \n",
    "u_ref = 20 # ML/week  - the target release \n",
    "u_0 = u_min/u_mean # (rescaling of u_min) \n",
    "u_1 = u_max/u_mean # (rescaling of u_max) \n",
    "u_ref = u_ref/u_mean # (rescaling of u_ref) \n",
    "s_ref_1 = 0.2 - storage fraction at which 1st change in slope occurs \n",
    "s_ref_2 = 0.8 - storage fraction at which 2nd change in slope occurs \n",    
    "### Operating policy defining points ###\n",
    "x0 = [0,       u_0]\n",
    "x1 = [s_ref_1, u_ref]\n",
    "x2 = [s_ref_2, u_ref]\n",
    "x3 = [1,       u_1]\n",
    "\n",
    "param = [x0, x1, x2, x3, u_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create the operating policy with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Release fraction ###\n",
    "u_frac = four_points_policy(param)/u_mean\n",
    "### Storage fraction ###\n",
    "s_frac = np.arange(0,1.01,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plotting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9feb994063460b80fb874bccb9cc24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='Storage fraction', scale=LinearScale(max=1.03, min=0.0)), Axis(label='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Axis characterisitcs\n",
    "x_sc_0 = LinearScale(min=0,max=1.03);y_sc_0 = LinearScale(min=0,max=4)\n",
    "x_ax_0 = Axis(label='Storage fraction', scale=x_sc_0)\n",
    "y_ax_0 = Axis(label='Release fraction', scale=y_sc_0, orientation='vertical')\n",
    "# Plot\n",
    "policy_function_points = Scatter(x = [x0[0], x1[0], x2[0], x3[0]], \n",
    "                            y = [x0[1], x1[1], x2[1], x3[1]],\n",
    "                            colors=['red'],stroke = 'lightgray',\n",
    "                            scales={'x': x_sc_0, 'y': y_sc_0},\n",
    "                            names = ['x0','x1','x2','x3'])\n",
    "policy_function_0 = Lines(x = s_frac, y = u_frac,\n",
    "                       colors=['blue'],stroke = 'lightgray',\n",
    "                       scales={'x': x_sc_0, 'y': y_sc_0})\n",
    "#Figure characteristics\n",
    "fig_0 = plt.Figure(marks = [policy_function_0,policy_function_points],title = 'Policy function', axes=[x_ax_0, y_ax_0],\n",
    "                    layout={'width': '500px', 'height': '450px'}, legend_style = {'fill': 'white', 'opacity': 0.5})\n",
    "widgets.VBox([fig_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the operating policy by trial and error (manual optimisation)\n",
    "We can now refine the parameters of the operating policy (that is, in our example, the coordinates of points x0,x1,x2,x3) by looking at which parameter combinations produce the best performance when simulated against the historical inflows, evaporation and water demand data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical inflows, evaporation and water demand data\n",
    "Let's assume we want to look at the last 100 weeks. We generate the historical inflows, evaporation, regulated releases and demand data as arrays of 100 random numbers with a given mean (loc) and standard deviation (scale). FP: I FIND THIS CONFUSING. SO FAR, WE SAID MULTIPLE TIMES THAT WE WERE GOING TO USE HISTORICAL DATA (INCLUDING IN THE TITLE OF THIS SECTION), THEN WE GET HERE AND WE ACTUALLY GENERATE SYNTHETIC DATA WITH A SIMPLE STOCHASTIC MODEL. THE READER WILL BE LOST! WE CAN USE EITHER ONE OR THE OTHER APPROACH (I HAVE NO PREFERENCE) BUT WE NEED TO CHOOSE ONE AND STICK TO IT! IF WE SAY WE USE HISTORICAL DATA, I WOULD EXPECT HERE A COMMAND TO UPLOAD DATA FROM A FILE, NOT TO GENERATE THE DATA (ALSO A MINOR COMMENT, IN CASE WE CHOOSE TO GO FOR THE HISTORICAL DATA APPROACH, THEN I WOULD NOT SAY THESE ARE THE DATA OF THE LAST 100 WEEKS. IT SUGGESTS TO ME THAT SOMEHOW THIS OPTIMISATION IS ALSO HAPPENING IN REAL-TIME, AS ONE USES THE DATA UP THE VERY LAST WEEK. IN REALITY, IT IS MORE OFTEN THE CASE THAT ONE USES RECENT DATA, BUT NOT AS RECENT AS LAST WEEK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # weeks\n",
    "I_hist = np.abs(np.random.normal(loc=20,scale=10,size=N))\n",
    "e_hist = np.abs(np.random.normal(loc=4,scale=1,size=N))\n",
    "d_hist = np.abs(np.random.normal(loc=20,scale=5,size=N))\n",
    "u_hist = np.abs(np.random.normal(loc=20,scale=1,size=N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the inflow time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "862d54cdea4d469ca8236964fd8f4c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='week', scale=LinearScale()), Axis(label='ML/week', orientation='vertic…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Axis characterisitcs\n",
    "x_sc_1 = LinearScale();y_sc_1 = LinearScale(min=0,max=40)\n",
    "x_ax_1 = Axis(label='week', scale=x_sc_1);y_ax_1 = Axis(label='ML/week', scale=y_sc_1, orientation='vertical')\n",
    "# Bar plot\n",
    "inflow_plot = plt.bar(np.arange(1,N+1),I_hist,colors=['blue'],stroke = 'lightgray',scales={'x': x_sc_1, 'y': y_sc_1},\n",
    "                      labels = ['inflow'], display_legend = True)\n",
    "#Figure characteristics\n",
    "fig_1a = plt.Figure(marks = [inflow_plot],title = 'Inflow for the last 100 weeks', axes=[x_ax_1, y_ax_1],\n",
    "                    layout={'min_width': '1000px', 'max_height': '300px'}, legend_style = {'fill': 'white', 'opacity': 0.5})\n",
    "widgets.VBox([fig_1a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the demand time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3711f4ae0daa48bc89be7e076a029fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(axes=[Axis(label='week', scale=LinearScale()), Axis(label='ML/week', orientation='vertic…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Bar plot (we use the same axis as the weekly inflows figure)\n",
    "demand_plot   = plt.bar(np.arange(1,N+1),d_hist,colors=['gray'],stroke = 'lightgray',opacities = [0.7]*N, \n",
    "                        labels = ['demand'], display_legend = True, \n",
    "                    stroke_width = 1,scales={'x': x_sc_1, 'y': y_sc_1})\n",
    "#Figure characteristics\n",
    "fig_1b = plt.Figure(marks = [demand_plot],title = 'Demand for the last 100 weeks', axes=[x_ax_1, y_ax_1],\n",
    "                    layout={'min_width': '1000px', 'max_height': '300px'}, legend_style = {'fill': 'white', 'opacity': 0.5})\n",
    "widgets.VBox([fig_1b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of other input parameters\n",
    "Let's define other variables that are needed for the reservoir system simulation, such as the reservoir storage capacity, the environmental compensation flow, etc. (FP: CAN WE ANTICIPATE THESE DEFINITIONS ABOVE, WHEN WE FIRST INTRODUCE THE OPERATING POLICY AND SET ITS PARAMETERS? IT WOULD MAKE THAT DESCRIPTION MUCH CLEARER (ONE WOULD UNDERSTAND THE LOGIC OF POINTS X0,X1,X2,X3 MUCH BETTER) AND AVOID DUPLICATIONS (FROM THE READER PERSPECTIVE HERE WE ARE OVERWRITING VARIABLES THAT WERE DEFINED ABOVE ALREADY...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constraints ###\n",
    "s_max = 150 #  (ML) Maximum storage (=reservoir capacity)\n",
    "s_min = 0 # (ML) Minimum storage (set to zero for now)\n",
    "u_max = 60 # (ML/week) Maximum release capacity\n",
    "env_min = 2 # (ML/week)   # Environmental compensation flow\n",
    "\n",
    "### Initial conditions ###\n",
    "s_0 = 80 # (ML) # Storage volume at the beginning of the simulation period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy function\n",
    "The policy function is delineated by 4 points: x0, x1, x2 and x3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mean = np.mean(u_hist)# mean historical release\n",
    "u_0 = env_min/u_mean # release fraction at the minimum storage level (= environmental flow / mean release)\n",
    "u_1 = u_max/u_mean # release at the maximum storage level (= max release capacity / mean release)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the reservoir simulation function\n",
    "Here we define a function that implements the reservoir simulation, that is, iteratively apply the mass balance equation and reconstruct the temporal evolution of the reservoir variables over the simulation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Submodules\n",
    "sys.path.append('../../Toolbox')\n",
    "from Reservoir_system_simulation.Res_sys_sim import Res_sys_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System objectives\n",
    "Let's assume that, we are interested in minimising the deficit with respect to a historical water demand, that is, to minimise the objective function:\n",
    "\n",
    "$$TSD = \\sum_{t=1}^{N} [ \\ max( \\ 0, \\ d(t)-u(t) \\ ) \\ ]^2 $$\n",
    "\n",
    "where N is the length of the simulation period that we are considering, and d(t) is the water demand for each time-interval in that period, and TSD stands for Total Squared Deficit. Notice that the function $max(0,...)$ enables us to only count the difference between demand d and release u when this is positive, that is, when the release u is smaller than the demand d, and a water shortage is indeed produced. Also, the squaring is a 'mathematical trick' to make sure that larger deficit amounts are given more weight than smaller ones. This translates the fact that small deficit amounts are easier to mitigate and hence more acceptable, while larger ones can cause disproportionately severe impacts and should be avoided as much as possible.\n",
    "\n",
    "We are also interested in minimising the chances that the reservoir level go below a minimum threshold. This could be for example, because the quality of the water deteriorates when levels are low, requiring more costly treatment. We measure how well this criterion is satisfied by the following objective function:\n",
    "\n",
    "$$MSV = \\sum_{t=1}^{N} [ \\ max ( \\ rc - s(t) , \\ 0) \\ ] $$\n",
    "\n",
    "where, again, N is the length of the simulation period, s is the reservoir storage, and rc is the minimum reservoir storage threshold that should preferably not be transpassed (MSV stands for Minimum Storage Violation). \n",
    "\n",
    "For our case, let's set this threshold to 40 ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = np.array([40]*(N+1)) # (ML)  minimum reservoir storage threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal release scheduling via interactive visualisation\n",
    "\n",
    "Now use the sliders to modify the release policy delineated by the policy function, in a way that minimises the Minimum Storage Violation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_1a,fig_1b,fig_1c, u_ref,s_ref_1,s_ref_2 = Interactive_policy_manual(N,\n",
    "                                                                        I_hist, e_hist, \n",
    "                                                                        s_0, s_min, s_max, \n",
    "                                                                        u_0, u_1, u_mean, u_max, \n",
    "                                                                        env_min, d_hist, \n",
    "                                                                        rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435c1e26254c40db85a12d57ac969389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(FloatSlider(value=1.0, continuous_update=False, description='u_re…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Box_layout = widgets.Layout(justify_content='center')\n",
    "widgets.VBox([widgets.HBox(\n",
    "    [widgets.VBox([u_ref,s_ref_1,s_ref_2],layout=Box_layout), fig_1a],layout=Box_layout),fig_1b,fig_1c],layout=Box_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From manual to automatic optimization approach\n",
    "As we have seen, when we deal with two conflicting objective, we cannot find a solution that optimise both simoultaneously. If we prioritize one objective, the other one is deteriorated: there is a trade-off between the two. It would then be interesting to explore this tradeoff, and find all the release schedules that produce a different optimal combination of the two objectives. However, this is too cumbersome to do manually. Here we then use a multi-objective optimisation algorithm to do that for us. \n",
    "\n",
    "To this end, we use the Python Platypus package, and the NSGAII algorithm implemented in it. For more information about these methods and tools, see [Deb et al, 2002](https://ieeexplore.ieee.org/document/996017) and the [Platypus webpage](https://platypus.readthedocs.io). The code to run the optimisation is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_optim(vars):\n",
    "\n",
    "    u_ref   = vars[0]\n",
    "    s_ref_1 = vars[1]\n",
    "    s_ref_2 = vars[2]\n",
    "    \n",
    "    x0 = [0,       u_0]\n",
    "    x1 = [s_ref_1, u_ref]\n",
    "    x2 = [s_ref_2, u_ref]\n",
    "    x3 = [1,       u_1]\n",
    "    param = [x0, x1, x2, x3, u_mean]\n",
    "    \n",
    "    Qreg = {'releases' : {'file_name' : 'Reservoir_operating_policy.Operating_policy_functions',\n",
    "                         'function' : 'four_points_policy',\n",
    "                         'param': param},\n",
    "            'inflows' : [],\n",
    "            'rel_inf' : []}\n",
    "    \n",
    "    Qenv, Qspill, u, I_reg, s, E = Res_sys_sim(I_hist, e_hist, s_0, s_min, s_max, env_min, d_hist, Qreg)\n",
    "    \n",
    "    TSD = (np.sum((np.maximum(d_hist-u,[0]*N))**2)).astype('int')\n",
    "    MSV = (np.sum((np.maximum(rc-s,[0]*(N+1))))).astype('int')\n",
    "    \n",
    "    constraints = [s_ref_2-s_ref_1]\n",
    "    \n",
    "    return [TSD, MSV], constraints\n",
    "\n",
    "problem = Problem(3,2,1)\n",
    "Real0 = Real(0,u_1); Real1 = Real(0, 1); Real2 = Real(0, 1)\n",
    "\n",
    "problem.types[:] = [Real0] + [Real1] + [Real2]\n",
    "problem.constraints[:] = \">=0\"\n",
    "problem.function = auto_optim\n",
    "\n",
    "population_size = 30\n",
    "algorithm = NSGAII(problem,population_size)\n",
    "algorithm.run(1000) # Number of iterations\n",
    "\n",
    "results1_optim = np.array([algorithm.result[i].objectives[0] for i in range(population_size)])\n",
    "results2_optim = np.array([algorithm.result[i].objectives[1] for i in range(population_size)])\n",
    "\n",
    "sol_optim = [algorithm.result[i].variables for i in range(population_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the optimisation results\n",
    "We can visualise the tradeoffs between the two objectives in one plot, called Pareto front, which displays the combination of the two objective values in correspondence to a set of optimised solutions. Click on one point in the Pareto front to visualise the release scheduling that generates that performance, and associated storage time series.  What do you think would be a balanced solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_pf, fig_2a,fig_2b,fig_2c = Interactive_policy_auto(N, \n",
    "                                                       I_hist, e_hist, \n",
    "                                                       s_0, s_min, s_max, \n",
    "                                                       u_0, u_1, u_mean, u_max,\n",
    "                                                       env_min, d_hist, \n",
    "                                                       rc, \n",
    "                                                       results1_optim,results2_optim,sol_optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7003ea8f7bc44f5d90fc18d3d4390295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Figure(animation_duration=1000, axes=[Axis(label='Total squared deficit [ML^2]',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Box_layout = widgets.Layout(justify_content='center')\n",
    "widgets.VBox([widgets.HBox(\n",
    "    [fig_pf, fig_2a],layout=Box_layout),fig_2b,fig_2c],layout=Box_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "Deb K. et al (2002) A fast and elitist multiobjective genetic algorithm: NSGA-II, IEEE Transactions on Evolutionary Computation, 6(2), 182-197, doi:10.1109/4235.996017.\n",
    "\n",
    "Dobson B. et al (2019) An argument-driven classification and comparison of reservoir operation optimization methods, Advances in Water Resources, 128, 74-86.\n",
    "\n",
    "Loucks D. P. et al (1981) Water resource systems planning and analysis, Prentice-Hall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questionnaire: Section 2 of 2\n",
    "Now that you are done with the Notebooks, could you please answer the questions of Section 2 of 2 of the questionnaire (click on Next button that you will find at the end of Section 1 of 2 of the questionnaire)?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
